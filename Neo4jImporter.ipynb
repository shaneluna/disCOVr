{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7921d946",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "1. Install APOC (https://neo4j.com/developer/neo4j-apoc/)\n",
    "- From neo4j desktop, select db > plugins on right > apoc > install and restart\n",
    "- In settings, add the following line to the bottom: apoc.import.file.enabled=true\n",
    "\n",
    "2. The below uses your default neo4j import location.<br>\n",
    "- Your default neo4j import location may vary by operating system (https://neo4j.com/developer/guide-import-csv/)\n",
    "- Linux / macOS / Docker - <neo4j-home>/import<br>\n",
    "- Windows - <neo4j-home>/import<br>\n",
    "- Debian / RPM - /var/lib/neo4j/import<br>\n",
    "\n",
    "If desired, you can modify acceptable import locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b5e033",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from py2neo import Graph\n",
    "import py2neo\n",
    "from py2neo.bulk import create_nodes\n",
    "import utilities as util\n",
    "import tarfile\n",
    "import shutil\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325650f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def compress_folder(path: str) -> str:\n",
    "    \"\"\"\n",
    "    Compress folder using gzip into current directory.\n",
    "    Return the name of new gzipped object.\n",
    "    \"\"\"\n",
    "    folder_name = os.path.basename(path)\n",
    "    new_file = f\"{folder_name}.tar.gz\"\n",
    "    tar = tarfile.open(new_file, \"w:gz\")\n",
    "    tar.add(path, arcname=folder_name)\n",
    "    tar.close()\n",
    "    return new_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378eabd0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def uncompress_folder(path: str) -> None:\n",
    "    \"\"\"\n",
    "    Uncompress gzipped folder.\n",
    "    \"\"\"\n",
    "    tar = tarfile.open(path)\n",
    "    dirname = os.path.dirname(path)\n",
    "    tar.extractall(dirname)\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5175a00c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def move_files_to_import(start_path: str, end_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Move files from folder start_path to be placed into end_path.\n",
    "    \"\"\"\n",
    "    # Compress\n",
    "    gzip_file = compress_folder(start_path)\n",
    "    # Move and overwrite with simiar name\n",
    "    moved_filepath = f\"{end_path}/{gzip_file}\"\n",
    "    print(gzip_file)\n",
    "    print(moved_filepath)\n",
    "    shutil.move(gzip_file, moved_filepath)\n",
    "    # Uncompress\n",
    "    uncompress_folder(moved_filepath)\n",
    "    # Delete tar file\n",
    "    delete_file(moved_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf087415",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def delete_file(path: str) -> None:\n",
    "    \"\"\"\n",
    "    Delete a file.\n",
    "    \"\"\"\n",
    "    os.remove(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7551ae09",
   "metadata": {},
   "source": [
    "#########\n",
    "Neo4j\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79e34e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constraints(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Create constraints and primary keys for graph database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        graph.run(\"CREATE CONSTRAINT ON (tweet:Tweet) ASSERT tweet.tweet_id IS UNIQUE\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (tweet:Tweet) ASSERT exists(tweet.tweet_id)\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (user:User) ASSERT user.user_id IS UNIQUE\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (user:User) ASSERT exists(user.user_id)\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "\n",
    "\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (twitter_topic:Twitter_Topic) ASSERT twitter_topic.twitter_topic_id IS UNIQUE\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (twitter_topic:Twitter_Topic) ASSERT exists(twitter_topic.twitter_topic_id)\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (article:Article) ASSERT article.article_id IS UNIQUE\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (article:Article) ASSERT exists(article.article_id)\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "    # Removing until dup urls removed from articles\n",
    "    # try: \n",
    "    #     graph.run(\"CREATE CONSTRAINT ON (article:Article) ASSERT article.url IS UNIQUE\")\n",
    "    # except py2neo.errors.ClientError:\n",
    "    #     pass\n",
    "\n",
    "\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (category:Category) ASSERT category.name IS UNIQUE\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass\n",
    "    try: \n",
    "        graph.run(\"CREATE CONSTRAINT ON (category:Category) ASSERT exists(category.name)\")\n",
    "    except py2neo.errors.ClientError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b249ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_tweets(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import tweet nodes to the graph database.\n",
    "    \"\"\"\n",
    "    files = util.get_files(\"./data/tweets/\", \"json\")\n",
    "    for file in files:\n",
    "        query = f\"\"\"\n",
    "        WITH 'file:///{file}' AS url \n",
    "        CALL apoc.load.json(url) YIELD value \n",
    "        UNWIND value.data AS data\n",
    "        WITH data, value.includes as includes\n",
    "        UNWIND includes.tweets AS include_tweets\n",
    "        MERGE (t1: Tweet {{tweet_id: data.id}})\n",
    "        SET t1.text = data.text,\n",
    "        t1.lang = data.lang,\n",
    "        t1.created_at = data.created_at,\n",
    "        t1.source = data.source,\n",
    "        t1.public_metrics_retweet_count = data.public_metrics.retweet_count,\n",
    "        t1.public_metrics_reply_count = data.public_metrics.reply_count,\n",
    "        t1.public_metrics_like_count = data.public_metrics.like_count,\n",
    "        t1.public_metrics_like_count = data.public_metrics.like_count\n",
    "        WITH data, t1, include_tweets\n",
    "        MERGE (t2: Tweet {{tweet_id: include_tweets.id}})\n",
    "        SET t2.text = include_tweets.text,\n",
    "        t2.lang = include_tweets.lang,\n",
    "        t2.created_at = include_tweets.created_at,\n",
    "        t2.source = include_tweets.source,\n",
    "        t2.public_metrics_retweet_count = data.public_metrics.retweet_count,\n",
    "        t2.public_metrics_reply_count = data.public_metrics.reply_count,\n",
    "        t2.public_metrics_like_count = data.public_metrics.like_count,\n",
    "        t2.public_metrics_like_count = data.public_metrics.like_count\n",
    "        \"\"\"\n",
    "        graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95051d9e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_users(graph: Graph) -> None: \n",
    "    \"\"\"\n",
    "    Import user nodes to the graph database.\n",
    "    \"\"\"\n",
    "    files = util.get_files(\"./data/tweets/\", \"json\")\n",
    "    for file in files:\n",
    "        query = f\"\"\"\n",
    "        WITH 'file:///{file}' AS url \n",
    "        CALL apoc.load.json(url) YIELD value \n",
    "        UNWIND value.data AS data\n",
    "        WITH data, value.includes as includes\n",
    "        UNWIND includes.users as include_users\n",
    "        MERGE (u1: User {{user_id: include_users.id}})\n",
    "        SET u1.username = include_users.username\n",
    "        SET u1.name = include_users.name\n",
    "        SET u1.description = include_users.description\n",
    "        SET u1.location = include_users.location\n",
    "        SET u1.created_at = include_users.created_at\n",
    "        SET u1.verified = include_users.verified\n",
    "        SET u1.public_metrics_followers_count = include_users.public_metrics.followers_count\n",
    "        SET u1.public_metrics_following_count = include_users.public_metrics.following_count\n",
    "        SET u1.public_metrics_tweet_count = include_users.public_metrics.tweet_count\n",
    "        SET u1.public_metrics_listed_count = include_users.public_metrics.listed_count\n",
    "        \"\"\"\n",
    "        graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d387b8",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_twitter_topics(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import twitter context annotations and their relationship for tweets.\n",
    "    \"\"\"\n",
    "    files = util.get_files(\"./data/tweets/\", \"json\")\n",
    "    for file in files:\n",
    "        query = f\"\"\"\n",
    "        WITH 'file:///{file}' AS url \n",
    "        CALL apoc.load.json(url) YIELD value \n",
    "        UNWIND value.data AS data\n",
    "        MERGE (t1: Tweet {{tweet_id:data.id}})\n",
    "        WITH t1, data.context_annotations as context_annotations\n",
    "        UNWIND context_annotations as context_annotation\n",
    "        MERGE (tt:Twitter_Topic {{twitter_topic_id: context_annotation.entity.id}})\n",
    "        SET tt.name = context_annotation.entity.name\n",
    "        SET tt.description = context_annotation.entity.description\n",
    "        SET tt.domain_id = context_annotation.domain.id\n",
    "        SET tt.domain_name = context_annotation.domain.name\n",
    "        SET tt.domain_description = context_annotation.domain.description\n",
    "        MERGE (t1)-[:associated_with]->(tt)\n",
    "        \"\"\"\n",
    "        graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226635f7",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_tweeted(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import tweeted edges between tweets and users to the graph database.\n",
    "    \"\"\"\n",
    "    files = util.get_files(\"./data/tweets/\", \"json\")\n",
    "    for file in files:\n",
    "        query = f\"\"\"\n",
    "        WITH 'file:///{file}' AS url \n",
    "        CALL apoc.load.json(url) YIELD value \n",
    "        UNWIND value.data AS data\n",
    "        WITH data, value.includes as includes\n",
    "        UNWIND includes.tweets as include_tweets\n",
    "        MERGE (u1:User {{user_id: data.author_id}})\n",
    "        MERGE (t1:Tweet {{tweet_id: data.id}})\n",
    "        MERGE (u1)-[:tweeted]->(t1)\n",
    "        MERGE (u2: User {{user_id: include_tweets.author_id}})\n",
    "        MERGE (t2: Tweet {{tweet_id: include_tweets.id}})\n",
    "        MERGE (u2)-[:tweeted]->(t2)\n",
    "        \"\"\"\n",
    "        graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbcdb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_referenced(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import referenced type edges between tweets to the graph database.\n",
    "    Includes retweeted, quoted, and replied_to.\n",
    "    \"\"\"\n",
    "    files = util.get_files(\"./data/tweets/\", \"json\")\n",
    "    for file in files:\n",
    "        query = f\"\"\"\n",
    "        WITH 'file:///{file}' AS url \n",
    "        CALL apoc.load.json(url) YIELD value \n",
    "        UNWIND value.data AS data\n",
    "        MERGE(t1: Tweet {{tweet_id: data.id}})\n",
    "        WITH data, t1\n",
    "        UNWIND data.referenced_tweets AS ref_tweets\n",
    "        MERGE (t2: Tweet {{tweet_id: ref_tweets.id}})\n",
    "        WITH t1,t2,ref_tweets\n",
    "        CALL apoc.create.relationship(t1, ref_tweets.type, null, t2) YIELD rel\n",
    "        RETURN t1, t2, rel\n",
    "        \"\"\"\n",
    "        graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed620508",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_mentioned(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import mentioned edges between tweets and users to the graph database.\n",
    "    \"\"\"\n",
    "    files = util.get_files(\"./data/tweets/\", \"json\")\n",
    "    for file in files:\n",
    "        query = f\"\"\"\n",
    "        WITH 'file:///{file}' AS url \n",
    "        CALL apoc.load.json(url) YIELD value \n",
    "        UNWIND value.data AS data\n",
    "        UNWIND data.entities.mentions AS mentions\n",
    "        MERGE (t1: Tweet {{tweet_id: data.id}})\n",
    "        MERGE (u1: User {{user_id: mentions.id}})\n",
    "        MERGE (t1)-[:mentioned]->(u1)\n",
    "        \"\"\"\n",
    "        graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047dd618",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Known dups in articles\n",
    "# Removing constraint on url until cleaned\n",
    "def import_articles(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import artcile nodes to the graph database.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///data/reCOVery/recovery-news-data.csv' AS row\n",
    "    MERGE (a:Article {{article_id: row.news_id}})\n",
    "    SET a.url = row.url, \n",
    "    a.publisher = row.publisher, \n",
    "    a.publish_date = row.publish_date, \n",
    "    a.author = row.author,\n",
    "    a.title = row.title,\n",
    "    a.body_text = row.body_text\n",
    "    RETURN a\n",
    "    \"\"\"\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0893b33",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_cited(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import cited relation for tweets and articles to the graph database.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///data/reCOVery/recovery-social-media-data.txt' AS row\n",
    "    MATCH (t:Tweet {{tweet_id: row.tweet_id}})\n",
    "    MATCH (a:Article {{article_id: row.news_id}})\n",
    "    MERGE (t)-[:cited]->(a)\n",
    "    \"\"\"\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107d0b0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_bias(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import bias for articles to the graph database.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///data/news_biases/news_biases.csv' AS row\n",
    "    MERGE (a:Article {{article_id: row.news_id}})\n",
    "    SET a.bias_title_decision = row.title_decision,\n",
    "    a.bias_title_score = row.title_score,\n",
    "    a.bias_content_decision = row.content_decision,\n",
    "    a.bias_content_score = row.content_score,\n",
    "    a.bias_domain = row.domain\n",
    "    RETURN a\n",
    "    \"\"\"\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b244c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_categories(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import categories to the graph database.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///data/news_topics/news_categories.csv' AS row\n",
    "    MERGE (c:Category {{name: row.category}} )\n",
    "    RETURN c\n",
    "    \"\"\"\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f43ab",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def import_categories_relationship(graph: Graph) -> None:\n",
    "    \"\"\"\n",
    "    Import category relationships for articles to the graph database.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    LOAD CSV WITH HEADERS FROM 'file:///data/news_topics/news_categories.csv' AS row\n",
    "    MERGE (a:Article {{article_id: row.news_id}})\n",
    "    MERGE (c:Category {{name: row.category}})\n",
    "    MERGE (a)-[:associated_with]->(c)\n",
    "    \"\"\"\n",
    "    graph.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761397df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = util.read_yaml_config(\"./secrets/config.yaml\")\n",
    "uri = config[\"neo4j\"][\"uri\"]\n",
    "user = config[\"neo4j\"][\"user\"]\n",
    "password = config[\"neo4j\"][\"password\"]\n",
    "\n",
    "graph = Graph(uri=uri, auth=(user, password))\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d8b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_import_location = \"/Users/lunez/Library/Application Support/Neo4j Desktop/Application/relate-data/dbmss/dbms-4374ec2b-7704-4595-a764-596a0e2fe227/import\"\n",
    "move_files_to_import(\"./data\", neo4j_import_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e95c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_constraints(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01067893",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# TWITTER NODES #\n",
    "import_tweets(graph)\n",
    "import_users(graph)\n",
    "import_referenced(graph)\n",
    "import_tweeted(graph)\n",
    "import_mentioned(graph)\n",
    "import_twitter_topics(graph)\n",
    "\n",
    "# ARTICLE NODES #\n",
    "import_articles(graph)\n",
    "import_cited(graph)\n",
    "import_bias(graph)\n",
    "import_categories(graph)\n",
    "import_categories_relationship(graph)\n",
    "\n",
    "print(time.time()-start)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
